{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA = Path('/data2/nelson_projs/ucsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from albumentations import (HorizontalFlip, RGBShift, ElasticTransform, GridDistortion,RandomBrightness ,ShiftScaleRotate, Normalize, Resize, Compose, OpticalDistortion,GaussNoise,Lambda)\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "from sklearn import model_selection\n",
    "#from fastai.vision import *\n",
    "\n",
    "from ranger import Ranger\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle: str = ''):\n",
    "    '''\n",
    "    Decode rle encoded mask.\n",
    "    \n",
    "    :param mask_rle: run-length as string formatted (start length)\n",
    "    :param shape: (height, width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    shape = (1400, 2100)\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order='F')\n",
    "\n",
    "\n",
    "def make_mask(df: pd.DataFrame, image_name: str='img.jpg', shape: tuple = (1400, 2100)):\n",
    "    \"\"\"\n",
    "    Create mask based on df, image name and shape.\n",
    "    \"\"\"\n",
    "    encoded_masks = df.loc[df['im_id'] == image_name, 'EncodedPixels']\n",
    "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
    "\n",
    "    for idx, label in enumerate(encoded_masks.values):\n",
    "        if label is not np.nan:\n",
    "            mask = rle_decode(label)\n",
    "            masks[:, :, idx] = mask\n",
    "            \n",
    "    return masks\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    \"\"\"\n",
    "    Convert image or mask.\n",
    "    \"\"\"\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    Convert mask to rle.\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        Lambda(image=preprocessing_fn),\n",
    "        Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{DATA}/train.csv')\n",
    "sub = pd.read_csv(f'{DATA}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train['im_id'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "#sub['label'] = sub['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "#sub['im_id'] = sub['Image_Label'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        HorizontalFlip(p=0.5),\n",
    "        ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.5, border_mode=0),\n",
    "        GridDistortion(p=0.5),\n",
    "        OpticalDistortion(p=0.5, distort_limit=2, shift_limit=0.5),\n",
    "        Resize(320, 640)\n",
    "    ]\n",
    "    return Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        Resize(320, 640)\n",
    "    ]\n",
    "    return Compose(test_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame = None, datatype: str = 'train', img_ids: np.array = None,\n",
    "                 transforms = Compose([HorizontalFlip(),ToTensor()]),\n",
    "                preprocessing=None):\n",
    "        self.df = df\n",
    "        if datatype != 'test':\n",
    "            self.data_folder = f\"{DATA}/train_images\"\n",
    "        else:\n",
    "            self.data_folder = f\"{DATA}/test_images\"\n",
    "        self.img_ids = img_ids\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.img_ids[idx]\n",
    "        mask = make_mask(self.df, image_name)\n",
    "        image_path = os.path.join(self.data_folder, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        if self.preprocessing:\n",
    "            preprocessed = self.preprocessing(image=img, mask=mask)\n",
    "            img = preprocessed['image']\n",
    "            mask = preprocessed['mask']\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mask_count = train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[0]).value_counts().\\\n",
    "reset_index().rename(columns={'index': 'img_id', 'Image_Label': 'count'})\n",
    "train_ids, valid_ids = train_test_split(id_mask_count['img_id'].values, random_state=42, stratify=id_mask_count['count'], test_size=0.1)\n",
    "#test_ids = sub['Image_Label'].apply(lambda x: x.split('_')[0]).drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "ACTIVATION = None\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=4, \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nelson/.local/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:2874: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  \"Using lambda is incompatible with multiprocessing. \"\n"
     ]
    }
   ],
   "source": [
    "num_workers = 0\n",
    "bs = 16\n",
    "\n",
    "train_dataset = CloudDataset(df=train, datatype='train', img_ids=train_ids, transforms = get_training_augmentation(), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "valid_dataset = CloudDataset(df=train, datatype='valid', img_ids=valid_ids, transforms = get_validation_augmentation(), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "\n",
    "#train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers)\n",
    "#valid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "#loaders = {\n",
    "#    \"train\": train_loader,\n",
    "#    \"valid\": valid_loader\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "data = DataBunch.create(train_dataset, valid_dataset, bs=16, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 320, 640]), torch.Size([16, 4, 320, 640]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(),y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricSeg(probability, truth, threshold=THRESHOLD, reduction='none'):\n",
    "    '''Calculates dice of positive and negative images seperately'''\n",
    "    '''probability and truth must be torch tensors'''\n",
    "    probability = torch.sigmoid(probability)\n",
    "    batch_size = len(truth)\n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float()\n",
    "        t = (truth > threshold).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0)\n",
    "        pos_index = torch.nonzero(t_sum >= 1)\n",
    "\n",
    "        dice_neg = (p_sum == 0).float()\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
    "\n",
    "        dice_neg = dice_neg[neg_index]\n",
    "        dice_pos = dice_pos[pos_index]\n",
    "        dice = torch.cat([dice_pos, dice_neg])\n",
    "\n",
    "        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
    "        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
    "        dice = dice.mean().item()\n",
    "\n",
    "        num_neg = len(neg_index)\n",
    "        num_pos = len(pos_index)\n",
    "\n",
    "    return dice, dice_neg, dice_pos, num_neg, num_pos\n",
    "\n",
    "class dices(LearnerCallback):\n",
    "    _order = -20 # Needs to run before the recorder, very CRITICAL step\n",
    "    def __init__(self,learn):\n",
    "        super().__init__(learn)\n",
    "        \n",
    "    def on_train_begin(self,**kwargs):\n",
    "        self.learn.recorder.add_metric_names(['dice','dice_neg','dice_pos','num_neg','num_pos'])\n",
    "        \n",
    "    def on_epoch_begin(self,**kwargs):\n",
    "        self.ttl_dice = []\n",
    "        self.ttl_dice_neg = []\n",
    "        self.ttl_dice_pos = []\n",
    "        self.ttl_num_neg = []\n",
    "        self.ttl_num_pos = []\n",
    "        self.ttl_lists = [self.ttl_dice,self.ttl_dice_neg,self.ttl_dice_pos,self.ttl_num_neg,self.ttl_num_pos]\n",
    "    \n",
    "    def on_batch_end(self,last_output,last_target,**kwargs):\n",
    "        dice, dice_neg, dice_pos, num_neg, num_pos = metricSeg(last_output,last_target)\n",
    "        self.ttl_dice.append(dice)\n",
    "        self.ttl_dice_neg.append(dice_neg)\n",
    "        self.ttl_dice_pos.append(dice_pos)\n",
    "        self.ttl_num_neg.append(num_neg)\n",
    "        self.ttl_num_pos.append(num_pos)\n",
    "    \n",
    "    def on_epoch_end(self,last_metrics,**kwargs):\n",
    "        extras = [sum(i)/float(len(i)) for i in self.ttl_lists]\n",
    "#         print(extras)\n",
    "        return add_metrics(last_metrics, extras)\n",
    "    \n",
    "class cutHorizonCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target,**kwargs):\n",
    "        last_input = to416(cutHorizontal(last_input))\n",
    "        last_target = to416(cutHorizontal(last_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optar = partial(Ranger)\n",
    "learn = Learner(data, model, metrics = [], opt_func=optar, loss_func = nn.BCEWithLogitsLoss(),callback_fns = dices).to_fp16()\n",
    "learn.path = Path(\"./fastai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set state called\n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "learn.fit_one_cycle(2,lr, callbacks=[\n",
    "#                                         dices(learn),\n",
    "#                                       cutHorizonCallback(),\n",
    "                                       SaveModelCallback(learn, every='epoch', monitor='loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
