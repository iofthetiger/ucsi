{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble from submission CSV only\n",
    "\n",
    "### This is a CPU only kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SIZE = 10000\n",
    "HOME = Path(os.environ[\"HOME\"])\n",
    "INPUT_DIR = Path(\"/kaggle/input\")\n",
    "SUBS = INPUT_DIR/\"subcsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check sub files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 378064\r\n",
      "-rw-r--r-- 1 root root 21579597 Nov 18 15:25 1110_154142_submission.csv\r\n",
      "-rw-r--r-- 1 root root 21251497 Nov 18 15:25 1114_090732_submission.csv\r\n",
      "-rw-r--r-- 1 root root 21085658 Nov 18 15:25 b5_fold_optimize_trian0.5_1114_150440_submission.csv\r\n",
      "-rw-r--r-- 1 root root 22902693 Nov 18 15:25 b5_pla_0.72_1573548650_submission.csv\r\n",
      "-rw-r--r-- 1 root root 23107546 Nov 18 15:25 b5_r2_1573525424_submission.csv\r\n",
      "-rw-r--r-- 1 root root 23211737 Nov 18 15:25 b6_fold_1114_121001_submission.csv\r\n",
      "-rw-r--r-- 1 root root 22315669 Nov 18 15:25 b6_ranger_submission.csv\r\n",
      "-rw-r--r-- 1 root root 20280347 Nov 18 15:25 b6_ver2_submission.csv\r\n",
      "-rw-r--r-- 1 root root 21339234 Nov 18 15:25 convex_1110_154142_submission.csv\r\n",
      "-rw-r--r-- 1 root root 20998002 Nov 18 15:25 convex_1111_161204_submission.csv\r\n",
      "-rw-r--r-- 1 root root 20853638 Nov 18 15:25 convex_b5_fold_optimize_trian0.5_1114_150440_submission.csv\r\n",
      "-rw-r--r-- 1 root root 21170814 Nov 18 15:25 convex_b6_fold_train0.5_optima_1116_080218_submission.csv\r\n",
      "-rw-r--r-- 1 root root 22968369 Nov 18 15:25 dpn_131_0.73_1573574797_submission.csv\r\n",
      "-rw-r--r-- 1 root root 22098201 Nov 18 15:25 emp_640x960_b6_single_1118_101912_submission.csv\r\n",
      "-rw-r--r-- 1 root root 21208385 Nov 18 15:25 emp_convex_1110_154142_submission.csv\r\n",
      "-rw-r--r-- 1 root root 21200903 Nov 18 15:25 emp_convex_384x567_1117_211214_submission.csv\r\n",
      "-rw-r--r-- 1 root root 18565765 Nov 18 15:25 emp_se_resnext50_640x960_5folds_1118_082125_submission.csv\r\n",
      "-rw-r--r-- 1 root root 20887775 Nov 18 15:25 resnext_miracle_raw.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {SUBS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set submission csv pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has to be an odd number\n",
    "sub_fnames = list([\n",
    "#     (\"resnext_miracle_raw.csv\", 0.3333333),# resnext 101 1st miracle 0.6596\n",
    "#     (\"1110_154142_submission.csv\",1/7), # enesemble \n",
    "#     (\"b5_pla_0.72_1573548650_submission.csv\",0.33333333)\n",
    "#     (\"b5_r2_1573525424_submission.csv\",0.3333333)finding\n",
    "#     (\"dpn_131_0.73_1573574797_submission.csv\",0.333333) #0.6443\n",
    "#     (\"b5_fold_optimize_trian0.5_1114_150440_submission.csv\",1/7), # 0.6587\n",
    "#     (\"b6_ver2_submission.csv\",1/7), #0.6527\n",
    "#     (\"b6_ranger_submission.csv\",1/7), #0.6556\n",
    "#     (\"1114_090732_submission.csv\",1/7), # resnext 101 5 folds 0.6569\n",
    "#     (\"b6_fold_1114_121001_submission.csv\",1/7), # b6 6 folds  0.6558\n",
    "#     (\"convex_b5_fold_optimize_trian0.5_1114_150440_submission.csv\", 0.3333333), # convex b5 5 folds\n",
    "#     (\"convex_b6_fold_train0.5_optima_1116_080218_submission.csv\", 0.3333333), # convex b6 5 bolds\n",
    "    (\"emp_convex_1110_154142_submission.csv\",0.3),\n",
    "    (\"emp_640x960_b6_single_1118_101912_submission.csv\",0.1),\n",
    "    (\"emp_se_resnext50_640x960_5folds_1118_082125_submission.csv\",0.3),\n",
    "    (\"emp_convex_384x567_1117_211214_submission.csv\",0.3),\n",
    "])\n",
    "sub_paths = list(SUBS/p[0] for p in sub_fnames)\n",
    "weighted = list(p[1] for p in sub_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.1, 0.3, 0.3]\n"
     ]
    }
   ],
   "source": [
    "print(weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bringOrder(df):\n",
    "    return df.sort_values(by=\"Image_Label\", ascending=True).reset_index().drop(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dfs = list(bringOrder(pd.read_csv(p)) for p in sub_paths)\n",
    "sample_df = sub_dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rle_decode(mask_rle: str = '', shape = (350,525 )):\n",
    "    '''\n",
    "    Decode rle encoded mask.\n",
    "    \n",
    "    :param mask_rle: run-length as string formatted (start length)\n",
    "    :param shape: (height, width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    \n",
    "    return img.reshape(shape, order='F')\n",
    "\n",
    "def post_process(probability, threshold=0.5, min_size = MIN_SIZE):\n",
    "    \"\"\"\n",
    "    Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored\n",
    "    \"\"\"\n",
    "    # don't remember where I saw it\n",
    "    mask = cv2.threshold(np.float32(probability), threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((350, 525), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num\n",
    "\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    Convert mask to rle.\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking with csv\n",
    "* CPU only\n",
    "* Not running any model at this point\n",
    "* CSV files has to be even number\n",
    "* The ensembled probability will go through the min size again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3698/3698 [02:00<00:00, 30.73it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoded_pixels = []\n",
    "for row_idx in tqdm(range(len(sample_df)//4)):\n",
    "    row_list = []\n",
    "    for cls in range(4):\n",
    "        img_pred = []\n",
    "        for i in range(len(sub_dfs)):\n",
    "            df = sub_dfs[i]\n",
    "            \n",
    "            rl = df.loc[row_idx*4+cls][\"EncodedPixels\"]\n",
    "            if type(rl)==str:\n",
    "                img_pred.append(rle_decode(rl)*weighted[i])\n",
    "            else:\n",
    "                img_pred.append(rle_decode(''))\n",
    "#         if row_idx == 0:\n",
    "#             print(img_pred)\n",
    "        # averaging over submissions\n",
    "        row_prob = np.sum(img_pred,axis=0)\n",
    "        row_pred, row_pred_num = post_process(row_prob)\n",
    "        if row_pred_num == 0:\n",
    "            encoded_pixels.append('')\n",
    "        else:\n",
    "            encoded_pixels.append(mask2rle(row_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['EncodedPixels'] = encoded_pixels\n",
    "sample_df.to_csv('csvs_%s_sub.csv'%(datetime.now().strftime(\"%m%d_%H%M%S\")), columns=['Image_Label', 'EncodedPixels'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
