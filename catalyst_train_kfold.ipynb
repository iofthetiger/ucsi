{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook (Catalyst)\n",
    "\n",
    "## Without threshold finding\n",
    "\n",
    "### Experiments\n",
    "\n",
    "* [x] Efficientnet b5 **PL:0.652**\n",
    "* [x] FP 16ï¼Œrefer to this [catalyst tutorial](https://github.com/catalyst-team/catalyst/blob/master/examples/notebooks/segmentation-tutorial.ipynb)\n",
    "    * The model will have gradient overflow after 5th epoch, everything else is okay\n",
    "* [x] Saving & Loading from JIT **PL:0.655**\n",
    "* [x] Ensemble\n",
    "* [x] 384x576\n",
    "* [x] polygon convex\n",
    "* [x] Test the funnel network again - totally not working\n",
    "* [x] Ranger optimizer \n",
    "    * [x] RADAM\n",
    "    * [x] Look Ahead\n",
    "* [x] Predict without threshold finding, save up training hours on valuable GPU resources\n",
    "* [ ] K-fold Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Apex for FP16\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex\n",
    "is_fp16_used = True\n",
    "```\n",
    "\n",
    "### Other Installations\n",
    "\n",
    "```\n",
    "pip install catalyst\n",
    "pip install pretrainedmodels\n",
    "pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "pip install pip pytorch-toolbelt\n",
    "pip install torchvision==0.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our starter kernel is from [this open kernel](https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import collections\n",
    "import time \n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "train_on_gpu = True\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations import pytorch as AT\n",
    "\n",
    "from catalyst.data import Augmentor\n",
    "from catalyst.dl import utils\n",
    "from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.contrib.models.segmentation import Unet\n",
    "from catalyst.dl.callbacks import DiceCallback, EarlyStoppingCallback, InferCallback, CheckpointCallback\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from catalyst.dl.core import Callback, CallbackOrder, RunnerState\n",
    "from collections import defaultdict\n",
    "from catalyst.contrib.optimizers import RAdam, Lookahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "RANGER = True\n",
    "\n",
    "EPOCHS = 40\n",
    "UPLOAD_WEIGHTS = True # upload weights to google cloud storage\n",
    "\n",
    "FP16 = False # Do we use half precision?\n",
    "fp16_params = dict(opt_level = \"O2\") if FP16 else None\n",
    "\n",
    "bs = 2 if FP16 else 4\n",
    "\n",
    "LOAD = False # Do we load a trained weights at the beginning\n",
    "LOAD_PATH = \"cata-eff-b5.pth\" # The model weight path, if we load a trained weights at the begining\n",
    "\n",
    "ENCODER = 'senet154' # Encoder model name\n",
    "ENCODER_WEIGHTS = 'imagenet' # Encoder pretrained weights\n",
    "DEVICE = 'cuda' \n",
    "\n",
    "ACTIVATION = None\n",
    "\n",
    "# Activate the threshold finding\n",
    "TH_FIND = True\n",
    "class_params = {0: (0.55, 10000), 1: (0.7, 10000), 2: (0.65, 10000), 3: (0.5, 10000)}\n",
    "\n",
    "MIN_SIZE_RANGE = 3\n",
    "MIN_SIZE = [0, 100, 1200, 5000,8000, 10000,12000][-MIN_SIZE_RANGE:]\n",
    "\n",
    "SIZE = (640,960)\n",
    "INPUT_SIZE = SIZE\n",
    "OUTPUT_SIZE = SIZE\n",
    "\n",
    "# Are we using train dataset to find the threshold\n",
    "FIND_TRAIN = True\n",
    "# How much percentage of train dataset are we using?\n",
    "SAMPLE_RATIO = .4\n",
    "\n",
    "K = 5\n",
    "\n",
    "JIT_PRED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 960) (640, 960)\n"
     ]
    }
   ],
   "source": [
    "print(INPUT_SIZE,OUTPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from utils_ucsi import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "Let's have a look at the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "HOME = Path(os.environ[\"HOME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data2/nelson_projs/ucsi'\n",
    "# os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have folders with train and test images, file with train image ids and masks and sample submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{path}/train.csv')\n",
    "sub = pd.read_csv(f'{path}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0011165.jpg_Fish</td>\n",
       "      <td>264918 937 266318 937 267718 937 269118 937 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0011165.jpg_Flower</td>\n",
       "      <td>1355565 1002 1356965 1002 1358365 1002 1359765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0011165.jpg_Gravel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011165.jpg_Sugar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002be4f.jpg_Fish</td>\n",
       "      <td>233813 878 235213 878 236613 878 238010 881 23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image_Label                                      EncodedPixels\n",
       "0    0011165.jpg_Fish  264918 937 266318 937 267718 937 269118 937 27...\n",
       "1  0011165.jpg_Flower  1355565 1002 1356965 1002 1358365 1002 1359765...\n",
       "2  0011165.jpg_Gravel                                                NaN\n",
       "3   0011165.jpg_Sugar                                                NaN\n",
       "4    002be4f.jpg_Fish  233813 878 235213 878 236613 878 238010 881 23..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5546 images in train dataset\n",
      "There are 3698 images in test dataset\n"
     ]
    }
   ],
   "source": [
    "n_train = len(os.listdir(f'{path}/train_images'))\n",
    "n_test = len(os.listdir(f'{path}/test_images'))\n",
    "print(f'There are {n_train} images in train dataset')\n",
    "print(f'There are {n_test} images in test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fish      5546\n",
       "Sugar     5546\n",
       "Flower    5546\n",
       "Gravel    5546\n",
       "Name: Image_Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Image_Label'].apply(lambda x: x.split('_')[1]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have ~5.5k images in train dataset and they can have up to 4 masks: Fish, Flower, Gravel and Sugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sugar     3751\n",
       "Gravel    2939\n",
       "Fish      2781\n",
       "Flower    2365\n",
       "Name: Image_Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[1]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2372\n",
       "3    1560\n",
       "1    1348\n",
       "4     266\n",
       "Name: Image_Label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[0]).value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are a lot of empty masks. In fact only 266 images have all four masks. It is important to remember this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train['im_id'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "\n",
    "sub['label'] = sub['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "sub['im_id'] = sub['Image_Label'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that masks can overlap. Also we can see that clouds are really similar to fish, flower and so on. Another important point: masks are often quite big and can have seemingly empty areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for modelling\n",
    "\n",
    "At first, let's create a list of unique image ids and the count of masks for images. This will allow us to make a stratified split based on this count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "class KFoldManager:\n",
    "    def __init__(self,x,k):\n",
    "        self.k = k\n",
    "        self.x = x\n",
    "        print(\"Initiate %s fold training\"%(self.k))\n",
    "        self.path = \"fold_%s_n%s.csv\"%(self.k,len(self.x))\n",
    "        self.loadGroup()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.k\n",
    "\n",
    "    def __getitem__(self, Nth):\n",
    "        print(\"Processing on %sth fold\"%(Nth))\n",
    "        train_ids = self.groups[self.groups.group!=Nth][\"ids\"].values\n",
    "        valid_ids = self.groups[self.groups.group==Nth][\"ids\"].values\n",
    "        return train_ids , valid_ids\n",
    "         \n",
    "    def idGroupDF(self):\n",
    "        print(\"Creating new group mapping\")\n",
    "        self.groups = pd.DataFrame({\"ids\":self.x,\"group\":np.random.choice(range(self.k),len(self.x))})\n",
    "        print(self.groups.group.value_counts())\n",
    "        return self.groups   \n",
    "    \n",
    "    def saveGroup(self):\n",
    "        self.groups.to_csv(self.path, index = False)\n",
    "        print(\"Saving to file:%s\"%(self.path))\n",
    "        \n",
    "    def loadGroup(self):\n",
    "        if os.path.exists(self.path):\n",
    "            self.groups = pd.read_csv(self.path)\n",
    "            print(self.groups.group.value_counts())\n",
    "        else:\n",
    "            self.idGroupDF()\n",
    "            self.saveGroup()\n",
    "            \n",
    "    def start(self,n):\n",
    "        print(\"=\"*70)\n",
    "        self.time1 = datetime.now()\n",
    "        print(\"fold\",n,self.time1.strftime(\"starting at %H:%M:%S\"))\n",
    "    \n",
    "    def end(self,n):\n",
    "        self.time2 = datetime.now()\n",
    "        print(\"fold\",n,self.time2.strftime(\"ending at %H:%M:%S\"))\n",
    "        delta = (self.time2-self.time1).seconds\n",
    "        print(\"This fold:%s h\\t%s m\\t%s s\"%(delta//3600,delta//60,delta%60))\n",
    "        print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame = None, datatype: str = 'train', img_ids: np.array = None,\n",
    "                 transforms = albu.Compose([albu.HorizontalFlip(),AT.ToTensor()]),\n",
    "                preprocessing=None):\n",
    "        self.df = df\n",
    "        if datatype != 'test':\n",
    "            self.data_folder = f\"{path}/train_images\"\n",
    "        else:\n",
    "            self.data_folder = f\"{path}/test_images\"\n",
    "        self.img_ids = img_ids\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.img_ids[idx]\n",
    "        mask = make_mask(self.df, image_name)\n",
    "        image_path = os.path.join(self.data_folder, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        if self.preprocessing:\n",
    "            preprocessed = self.preprocessing(image=img, mask=mask)\n",
    "            img = preprocessed['image']\n",
    "            mask = preprocessed['mask']\n",
    "            \n",
    "        return img,mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - Fold Traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiate 5 fold training\n",
      "0    1146\n",
      "4    1109\n",
      "3    1108\n",
      "2    1101\n",
      "1    1082\n",
      "Name: group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "id_mask_count = train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[0]).value_counts().\\\n",
    "reset_index().rename(columns={'index': 'img_id', 'Image_Label': 'count'})\n",
    "\n",
    "# Test ids\n",
    "test_ids = sub['Image_Label'].apply(lambda x: x.split('_')[0]).drop_duplicates().values\n",
    "# Kfold manager\n",
    "kfm = KFoldManager(id_mask_count['img_id'].values,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "fold 0 starting at 08:43:41\n",
      "Processing on 0th fold\n",
      "Train:\t4400\tValid:\t1146\n",
      "[Fold 0]\tStructuring Model]\n",
      "[Fold 0]\tCreating datasets, dataloaders]\n",
      "[Fold 0]\tPutting model to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/conda_envs/catalyst/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:2881: UserWarning:\n",
      "\n",
      "Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0]\tRun training\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(len(kfm)):\n",
    "    if TRAIN==False:\n",
    "        print(\"not run training\")\n",
    "        contin\n",
    "    kfm.start(fold)\n",
    "    train_ids,valid_ids = kfm[fold]\n",
    "    print(\"Train:\\t%s\\tValid:\\t%s\"%(len(train_ids),len(valid_ids)))\n",
    "    \n",
    "    print(\"[Fold %s]\\tStructuring Model]\"%(fold))\n",
    "    model = smp.FPN(\n",
    "        encoder_name=ENCODER, \n",
    "        encoder_weights=ENCODER_WEIGHTS, \n",
    "        classes=4, \n",
    "        activation=ACTIVATION,\n",
    "    )\n",
    "    preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "    \n",
    "    num_workers = 4\n",
    "    \n",
    "    print(\"[Fold %s]\\tCreating datasets, dataloaders]\"%(fold))\n",
    "    train_dataset = CloudDataset(df=train, datatype='train', img_ids=train_ids, transforms = get_training_augmentation(), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "    valid_dataset = CloudDataset(df=train, datatype='valid', img_ids=valid_ids, transforms = get_validation_augmentation(), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    loaders = {\n",
    "        \"train\": train_loader,\n",
    "        \"valid\": valid_loader\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    logdir = \"./logs/seg_%s_f%s\"%(ENCODER, fold)\n",
    "    \n",
    "    # model, criterion, optimizer\n",
    "    opt_class = RAdam if RANGER else torch.optim.Adam\n",
    "    \n",
    "    op_list = [\n",
    "        {'params': model.decoder.parameters(), 'lr': 1e-2}, \n",
    "        {'params': model.encoder.parameters(), 'lr': 1e-3},  # Pretrained section of the model using smaller lr\n",
    "    ]\n",
    "        \n",
    "    # optimizer, loss function and runner    \n",
    "    optimizer_ = opt_class(op_list, weight_decay=3e-4)\n",
    "    optimizer = Lookahead(optimizer_) if RANGER else optimizer_\n",
    "    #scheduler = ReduceLROnPlateau(optimizer, factor=0.18, patience=2)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=1)\n",
    "    criterion = smp.utils.losses.BCEDiceLoss(eps=1.)\n",
    "    \n",
    "    print(\"[Fold %s]\\tPutting model to cuda\"%(fold))\n",
    "    model = model.cuda()\n",
    "    runner = SupervisedRunner()\n",
    "    \n",
    "    print(\"[Fold %s]\\tRun training\"%(fold))\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loaders=loaders,\n",
    "        callbacks=[DiceCallback(), EarlyStoppingCallback(patience=5, min_delta=0.001)],\n",
    "        logdir=logdir,\n",
    "        num_epochs=EPOCHS,\n",
    "        fp16=fp16_params,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"[Fold %s]\\tTaking model out of cuda\"%(fold))\n",
    "    model = model.cpu()\n",
    "    \n",
    "    # end timer \n",
    "    kfm.end(fold)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate all model weigths\n",
    "log_dirs = list({\"path\":HOME/\"ucsi\"/\"logs\"/str(\"seg_%s_f%s\"%(ENCODER, fold))/\"checkpoints\"/\"best.pth\",\n",
    "                 \"encoder\":ENCODER } for fold in range(K))\n",
    "print(log_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload weights to google cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if UPLOAD_WEIGHTS:\n",
    "    from utils_google import download_blob,upload_blob,list_blobs_with_prefix\n",
    "    for i in range(len(log_dirs)):\n",
    "        upload_blob(\"milkyway\",str(log_dirs[i][\"path\"]),\"pth/%s_f%s.pth\"%(ENCODER,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(path,encoder):\n",
    "    \"\"\"\n",
    "    load a single model from path and encoder information\n",
    "    \"\"\"\n",
    "    model = smp.FPN(\n",
    "        encoder_name=ENCODER, \n",
    "        encoder_weights=None, \n",
    "        classes=4, \n",
    "        activation=ACTIVATION,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(path)[\"model_state_dict\"])\n",
    "    model = model.cuda()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(loadModel(i[\"path\"], i[\"encoder\"]) for i in log_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ensModel(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        self.models = models\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        res = []\n",
    "        x = x.cuda()\n",
    "        with torch.no_grad():\n",
    "            for m in self.models:\n",
    "                res.append(m(x))\n",
    "        res = torch.stack(res)\n",
    "        return torch.mean(res, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensModel(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_cb = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# A modified version to save memory when do the inference\n",
    "class InferCallback(Callback):\n",
    "    def __init__(self, out_dir=None, out_prefix=None):\n",
    "        super().__init__(CallbackOrder.Internal)\n",
    "        self.out_dir = out_dir\n",
    "        self.out_prefix = out_prefix\n",
    "        self.predictions = defaultdict(lambda: [])\n",
    "        self._keys_from_state = [\"out_dir\", \"out_prefix\"]\n",
    "\n",
    "    def on_stage_start(self, state: RunnerState):\n",
    "        for key in self._keys_from_state:\n",
    "            value = getattr(state, key, None)\n",
    "            if value is not None:\n",
    "                setattr(self, key, value)\n",
    "        # assert self.out_prefix is not None\n",
    "        if self.out_dir is not None:\n",
    "            self.out_prefix = str(self.out_dir) + \"/\" + str(self.out_prefix)\n",
    "        if self.out_prefix is not None:\n",
    "            os.makedirs(os.path.dirname(self.out_prefix), exist_ok=True)\n",
    "\n",
    "    def on_loader_start(self, state: RunnerState):\n",
    "        self.predictions = {\"logits\":list()}\n",
    "    \n",
    "    def on_batch_end(self, state: RunnerState):\n",
    "        dct = state.output\n",
    "        dct = {key: value.detach().cpu().numpy() for key, value in dct.items()}\n",
    "        for key, value in dct.items():\n",
    "            pred = np.zeros((len(value)*4, 350, 525), dtype = np.float16)\n",
    "#             print(value.shape,pred.shape)\n",
    "            for i,output in enumerate(value):\n",
    "                for j, probability in enumerate(output):\n",
    "                    probability = cv2.resize(probability, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "                    pred[i * 4 + j, :, :] = probability\n",
    "            self.predictions[\"logits\"].append(pred)\n",
    "        print(\">\",end = \"\")\n",
    "\n",
    "    def on_loader_end(self, state: RunnerState):\n",
    "        self.predictions = {\n",
    "            key: np.concatenate(value, axis=0)\n",
    "            for key, value in self.predictions.items()\n",
    "        }\n",
    "\n",
    "infer_cb.append(InferCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_pixels = []\n",
    "\n",
    "# Rebuild data loader\n",
    "\n",
    "if TH_FIND:\n",
    "    train_dataset = CloudDataset(df=train, datatype='train', img_ids=train_ids, transforms = get_training_augmentation(), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=bs*8, shuffle=False, num_workers=num_workers)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=bs*8, shuffle=False, num_workers=num_workers)\n",
    "    loaders = {\"infer\": train_loader if FIND_TRAIN else valid_loader}\n",
    "    # Run inference through model\n",
    "    print(\"Running inference:\")\n",
    "    print(\"=\"*(len(train_dataset if FIND_TRAIN else valid_dataset)//(bs*8)))\n",
    "    runner.infer(\n",
    "        model=model,\n",
    "        loaders=loaders,\n",
    "        callbacks=infer_cb,\n",
    "    )\n",
    "    valid_masks = []\n",
    "    print(\"Build valid mask on :\\t%s\"%(\"train data\" if FIND_TRAIN else \"valid data\"))\n",
    "    for i, batch in enumerate(tqdm.tqdm(train_dataset if FIND_TRAIN else valid_dataset)):\n",
    "        image, mask = batch\n",
    "        for m in mask: # for each seg class\n",
    "            if m.shape != (350, 525):\n",
    "                m = cv2.resize(m, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "            valid_masks.append(m)\n",
    "    probabilities  = runner.callbacks[0].predictions[\"logits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal values\n",
    "\n",
    "First of all, my thanks to @samusram for finding a mistake in my validation\n",
    "https://www.kaggle.com/c/understanding_cloud_organization/discussion/107711#622412\n",
    "\n",
    "And now I find optimal values separately for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TH_FIND:\n",
    "    class_params = {}\n",
    "    for class_id in range(4):\n",
    "        print(class_id)\n",
    "        attempts = []\n",
    "        for t in range(30, 75, 5):\n",
    "            t /= 100\n",
    "            for ms in [0, 100, 1200, 5000, 10000]:\n",
    "                masks = []\n",
    "                for i in range(class_id, len(probabilities), 4):\n",
    "                    probability = probabilities[i]\n",
    "                    predict, num_predict = post_process(sigmoid(probability), t, ms)\n",
    "                    masks.append(predict)\n",
    "    \n",
    "                d = []\n",
    "                for i, j in zip(masks, valid_masks[class_id::4]):\n",
    "                    if (i.sum() == 0) & (j.sum() == 0):\n",
    "                        d.append(1)\n",
    "                    else:\n",
    "                        d.append(dice(i, j))\n",
    "    \n",
    "                attempts.append((t, ms, np.mean(d)))\n",
    "    \n",
    "        attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n",
    "    \n",
    "    \n",
    "        attempts_df = attempts_df.sort_values('dice', ascending=False)\n",
    "        print(attempts_df.head())\n",
    "        best_threshold = attempts_df['threshold'].values[0]\n",
    "        best_size = attempts_df['size'].values[0]\n",
    "        \n",
    "        class_params[class_id] = (best_threshold, best_size)\n",
    "else:\n",
    "    print(\"Not running threshold finding, using default threshold config\")\n",
    "print(class_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CloudDataset(df=sub, datatype='test', img_ids=test_ids, transforms = get_validation_augmentation(), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "loaders = {\"test\": test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_pixels = []\n",
    "image_id = 0\n",
    "runner = SupervisedRunner()\n",
    "runner.model = model\n",
    "for i, test_batch in enumerate(tqdm.tqdm(loaders['test'])):\n",
    "    runner_out = runner.predict_batch({\"features\": test_batch[0].cuda()})['logits']\n",
    "    for i, batch in enumerate(runner_out):\n",
    "        for probability in batch:\n",
    "            \n",
    "            probability = probability.cpu().detach().numpy()\n",
    "            if probability.shape != (350, 525):\n",
    "                probability = cv2.resize(probability, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "            predict, num_predict = post_process(sigmoid(probability), class_params[image_id % 4][0], class_params[image_id % 4][1])\n",
    "            if num_predict == 0:\n",
    "                encoded_pixels.append('')\n",
    "            else:\n",
    "                r = mask2rle(predict)\n",
    "                encoded_pixels.append(r)\n",
    "            image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['EncodedPixels'] = encoded_pixels\n",
    "sub.to_csv('%s_submission.csv'%(int(datetime.now().timestamp())), columns=['Image_Label', 'EncodedPixels'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:catalyst]",
   "language": "python",
   "name": "conda-env-catalyst-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
